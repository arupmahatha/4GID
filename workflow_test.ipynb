{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Generation and Analysis Workflow Test\n",
    "\n",
    "This notebook demonstrates the complete workflow using multiple LLMs:\n",
    "1. Generating SQL using DeepSeek and Mistral\n",
    "2. Extracting entities from the SQL\n",
    "3. Matching values in the SQL\n",
    "4. Refining the generated SQL\n",
    "5. Executing the refined SQL\n",
    "6. Analyzing the results\n",
    "\n",
    "Each step uses DeepSeek and Mistral for generation, with Gemini as the decision maker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_config.llm_call import generate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show the FPS Inspection Allocation Report from May 1, 2025 to May 14, 2025 for district 209, sub-division 07001, block 01116, panchayat 000377, assigned by dayakarB, and assigned to 40015297.\n"
     ]
    }
   ],
   "source": [
    "# Test queries\n",
    "test_queries = [\n",
    "    \"Show the FPS Inspection Allocation Report from May 1, 2025 to May 14, 2025 for district 209, sub-division 07001, block 01116, panchayat 000377, assigned by dayakarB, and assigned to 40015297.\"\n",
    "]\n",
    "\n",
    "# Select which query to test\n",
    "user_query = test_queries[0]\n",
    "\n",
    "print(user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SQL Generation Test with Multiple LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating SQL with Model 1...\n",
      "\n",
      "Generated SQL: SELECT \n",
      "    is.id AS inspection_scheduling_id,\n",
      "    is.date_of_inspection,\n",
      "    is.inspection_status,\n",
      "    is.inspection_type,\n",
      "    is.remarks,\n",
      "    fps.id AS fair_price_shop_id,\n",
      "    fps.fps_name,\n",
      "    fps.fps_uid,\n",
      "    p.panchayat_name,\n",
      "    p.panchayat_uid,\n",
      "    b.block_name,\n",
      "    b.block_uid,\n",
      "    sd.subdivision_name,\n",
      "    sd.subdivision_uid,\n",
      "    d.district_name,\n",
      "    d.district_uid,\n",
      "    creator.username AS assigned_by,\n",
      "    assignee.username AS assigned_to\n",
      "FROM \n",
      "    inspection_schedulings is\n",
      "JOIN \n",
      "    inspection_schedulings_fps_id_lnk isf ON is.id = isf.inspection_scheduling_id\n",
      "JOIN \n",
      "    fair_price_shops fps ON isf.fair_price_shop_id = fps.id\n",
      "JOIN \n",
      "    godowns_panchayat_lnk gpl ON fps.godown_id = gpl.godown_id\n",
      "JOIN \n",
      "    panchayats p ON gpl.panchayat_id = p.id\n",
      "JOIN \n",
      "    panchayats_block_lnk pbl ON p.id = pbl.panchayat_id\n",
      "JOIN \n",
      "    blocks b ON pbl.block_id = b.id\n",
      "JOIN \n",
      "    subdivisions sd ON b.subdivision_id = sd.id\n",
      "JOIN \n",
      "    districts d ON sd.district_id = d.id\n",
      "JOIN \n",
      "    inspection_schedulings_assigned_to_lnk isa ON is.id = isa.inspection_scheduling_id\n",
      "JOIN \n",
      "    poims_users assignee ON isa.poims_user_id = assignee.id\n",
      "JOIN \n",
      "    poims_users creator ON is.created_by_id = creator.id\n",
      "WHERE \n",
      "    is.date_of_inspection BETWEEN '2025-05-01' AND '2025-05-14'\n",
      "    AND d.id = 209\n",
      "    AND sd.id = 07001\n",
      "    AND b.id = 01116\n",
      "    AND p.id = 000377\n",
      "    AND creator.username = 'dayakarB'\n",
      "    AND assignee.id = 40015297\n",
      "ORDER BY \n",
      "    is.date_of_inspection, fps.fps_name;\n",
      "\n",
      "Generating SQL with Model 2...\n",
      "\n",
      "Generated SQL: SELECT\n",
      "is.id AS inspection_scheduling_id,\n",
      "is.date_of_inspection,\n",
      "is.inspection_status,\n",
      "is.inspection_type,\n",
      "is.remarks,\n",
      "fps.id AS fair_price_shop_id,\n",
      "fps.fps_name,\n",
      "fps.fps_uid,\n",
      "p.panchayat_name,\n",
      "p.panchayat_uid,\n",
      "b.block_name,\n",
      "b.block_uid,\n",
      "sd.subdivision_name,\n",
      "sd.subdivision_uid,\n",
      "d.district_name,\n",
      "d.district_uid,\n",
      "creator.username AS assigned_by,\n",
      "assignee.username AS assigned_to\n",
      "FROM\n",
      "inspection_schedulings is\n",
      "JOIN\n",
      "inspection_schedulings_fps_id_lnk isf ON is.id = isf.inspection_scheduling_id\n",
      "JOIN\n",
      "fair_price_shops fps ON isf.fair_price_shop_id = fps.id\n",
      "JOIN\n",
      "godowns_panchayat_lnk gpl ON fps.godown_id = gpl.godown_id\n",
      "JOIN\n",
      "panchayats p ON gpl.panchayat_id = p.id\n",
      "JOIN\n",
      "panchayats_block_lnk pbl ON p.id = pbl.panchayat_id\n",
      "JOIN\n",
      "blocks b ON pbl.block_id = b.id\n",
      "JOIN\n",
      "subdivisions sd ON b.subdivision_id = sd.id\n",
      "JOIN\n",
      "districts d ON sd.district_id = d.id\n",
      "JOIN\n",
      "inspection_schedulings_assigned_to_lnk isa ON is.id = isa.inspection_scheduling_id\n",
      "JOIN\n",
      "poims_users assignee ON isa.poims_user_id = assignee.id\n",
      "JOIN\n",
      "poims_users creator ON is.created_by_id = creator.id\n",
      "WHERE\n",
      "is.date_of_inspection BETWEEN '2025-05-01' AND '2025-05-14'\n",
      "AND d.id\n",
      "\n",
      "Schema Info: ongoing_inspections_panchayat_lnk (id, ongoing_inspection_id, panchayat_id)\n",
      "\n",
      "panchayats_block_lnk (id, panchayat_id, block_id, panchayat_ord)\n",
      "\n",
      "panchayats (id, document_id, panchayat_name, panchayat_uid, created_at, updated_at, published_at, created_by_id, updated_by_id, locale)\n",
      "\n",
      "godowns_panchayat_lnk (id, godown_id, panchayat_id, godown_ord)\n",
      "\n",
      "villages_panchayat_lnk (id, village_id, panchayat_id, village_ord)\n",
      "\n",
      "inspection_schedulings_fps_id_lnk (id, inspection_scheduling_id, fair_price_shop_id)\n",
      "\n",
      "ongoing_inspections_fps_lnk (id, ongoing_inspection_id, fair_price_shop_id)\n",
      "\n",
      "inspection_schedulings (id, document_id, date_of_inspection, remarks, created_at, updated_at, published_at, created_by_id, updated_by_id, locale, inspection_status, inspection_type)\n",
      "\n",
      "fps_stock_datas (id, document_id, phh_rice, aay_rice, phh_wheat, aay_wheat, families_associated, phh_ration_cards, phh_members, aay_ration_cards, aay_members, stock_date, created_at, updated_at, published_at, created_by_id, updated_by_id, locale)\n",
      "\n",
      "inspection_schedulings_assigned_to_lnk (id, inspection_scheduling_id, poims_user_id)\n",
      "\n",
      "\n",
      "Validator chose Model 1's query\n"
     ]
    }
   ],
   "source": [
    "from engine.generator import SQLGenerator\n",
    "\n",
    "def test_generator(model1=\"deepseek-chat\", model2=\"mistralai/Mistral-7B-Instruct-v0.3\", validator=\"gemini\"):\n",
    "    \"\"\"Test SQL generation functionality with multiple LLMs\"\"\"\n",
    "    generator = SQLGenerator()\n",
    "    \n",
    "    try:\n",
    "        # Generate SQL using Model 1\n",
    "        print(\"\\nGenerating SQL with Model 1...\")\n",
    "        model1_results = generator.main_generator(user_query, llm_model=model1)\n",
    "        print(\"\\nGenerated SQL:\", model1_results['generated_sql'])\n",
    "        \n",
    "        # Generate SQL using Model 2\n",
    "        print(\"\\nGenerating SQL with Model 2...\")\n",
    "        model2_results = generator.main_generator(user_query, llm_model=model2)\n",
    "        print(\"\\nGenerated SQL:\", model2_results['generated_sql'])\n",
    "\n",
    "        print(\"\\nSchema Info:\", model1_results['formatted_metadata'])\n",
    "        \n",
    "        # Use Validator to decide which SQL to use\n",
    "        decision_prompt = f\"\"\"Compare these two Generated SQLs for the given query and choose the better one:\n",
    "        \n",
    "        Input Query: {user_query}\n",
    "        \n",
    "        Schema Info: {model1_results['formatted_metadata']}\n",
    "        \n",
    "        Query 1 (Model 1):\n",
    "        Generated SQL: {model1_results['generated_sql']}\n",
    "        \n",
    "        Query 2 (Model 2):\n",
    "        Generated SQL: {model2_results['generated_sql']}\n",
    "        \n",
    "        Consider the input query, schema info, and the generated SQLs when making your decision.\n",
    "        Respond with only '1' or '2' to indicate which output is better.\"\"\"\n",
    "        \n",
    "        decision = generate_text(decision_prompt, model=validator)\n",
    "        \n",
    "        # Use the chosen query\n",
    "        if decision.strip() == '1':\n",
    "            print(\"\\nValidator chose Model 1's query\")\n",
    "            chosen_results = model1_results\n",
    "        else:\n",
    "            print(\"\\nValidator chose Model 2's query\")\n",
    "            chosen_results = model2_results\n",
    "        \n",
    "        return chosen_results['generated_sql']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "generated_sql = test_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entity Extraction Test with Multiple LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting entities with Model 1...\n",
      "\n",
      "Extracted Entities:\n",
      "---\n",
      "Table: poims_users\n",
      "Column: username\n",
      "Value: dayakarB\n",
      "\n",
      "Extracting entities with Model 2...\n",
      "\n",
      "Extracted Entities:\n",
      "\n",
      "Validator chose Model 1's entities\n"
     ]
    }
   ],
   "source": [
    "from engine.entity_extractor import EntityExtractor\n",
    "\n",
    "def test_entity_extractor(sql_query, model1=\"deepseek-chat\", model2=\"mistralai/Mistral-7B-Instruct-v0.3\", validator=\"gemini\"):\n",
    "    \"\"\"Test entity extraction functionality with multiple LLMs\"\"\"\n",
    "    extractor = EntityExtractor()\n",
    "    \n",
    "    try:\n",
    "        # Extract entities using Model 1\n",
    "        print(\"\\nExtracting entities with Model 1...\")\n",
    "        model1_results = extractor.main_entity_extractor(sql_query, llm_model=model1)\n",
    "        print(\"\\nExtracted Entities:\")\n",
    "        for entity in model1_results:\n",
    "            print(\"---\")\n",
    "            print(f\"Table: {entity['table']}\")\n",
    "            print(f\"Column: {entity['column']}\")\n",
    "            print(f\"Value: {entity['value']}\")\n",
    "        \n",
    "        # Extract entities using Model 2\n",
    "        print(\"\\nExtracting entities with Model 2...\")\n",
    "        model2_results = extractor.main_entity_extractor(sql_query, llm_model=model2)\n",
    "        print(\"\\nExtracted Entities:\")\n",
    "        for entity in model2_results:\n",
    "            print(\"---\")\n",
    "            print(f\"Table: {entity['table']}\")\n",
    "            print(f\"Column: {entity['column']}\")\n",
    "            print(f\"Value: {entity['value']}\")\n",
    "        \n",
    "        # Use Validator to decide which entities to use\n",
    "        decision_prompt = f\"\"\"Compare these two sets of extracted entities for the input SQL and choose the better one:\n",
    "        \n",
    "        Input SQL: {sql_query}\n",
    "        \n",
    "        Entities 1 (Model 1):\n",
    "        Extracted Entities: {model1_results}\n",
    "        \n",
    "        Entities 2 (Model 2):\n",
    "        Extracted Entities: {model2_results}\n",
    "        \n",
    "        Consider the input SQL and both the extracted entities when making your decision.\n",
    "        Respond with only '1' or '2' to indicate which set is better.\"\"\"\n",
    "        \n",
    "        decision = generate_text(decision_prompt, model=validator)\n",
    "        \n",
    "        # Use the chosen entities\n",
    "        if decision.strip() == '1':\n",
    "            print(\"\\nValidator chose Model 1's entities\")\n",
    "            chosen_results = model1_results\n",
    "        else:\n",
    "            print(\"\\nValidator chose Model 2's entities\")\n",
    "            chosen_results = model2_results\n",
    "        \n",
    "        return chosen_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if generated_sql:\n",
    "    extracted_entities = test_entity_extractor(generated_sql)\n",
    "else:\n",
    "    print(\"Skipping entity extraction as no SQL was generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Value Matching Test with Multiple LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Mappings:\n",
      "---\n",
      "Original: 'dayakarB'\n",
      "Matched: 'dayakarB'\n",
      "Score: 100\n"
     ]
    }
   ],
   "source": [
    "from engine.value_matcher import ValueMatcher\n",
    "\n",
    "def test_value_matcher(extracted_entities):\n",
    "    \"\"\"Test value matching functionality\"\"\"\n",
    "    matcher = ValueMatcher()\n",
    "    \n",
    "    try:\n",
    "        value_mappings = []\n",
    "        for entity in extracted_entities:\n",
    "            match = matcher.main_value_matcher(entity)\n",
    "            value_mappings.extend(match)\n",
    "        \n",
    "        print(\"Value Mappings:\")\n",
    "        for mapping in value_mappings:\n",
    "            print(\"---\")\n",
    "            print(f\"Original: '{mapping['original_value']}'\")\n",
    "            print(f\"Matched: '{mapping['matched_value']}'\")\n",
    "            print(f\"Score: {mapping['score']}\")\n",
    "        \n",
    "        return value_mappings\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if extracted_entities:\n",
    "    value_mappings = test_value_matcher(extracted_entities)\n",
    "else:\n",
    "    print(\"Skipping value matching as no entities were extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SQL Refinement Test with Multiple LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Refining SQL with Model 1...\n",
      "\n",
      "Refined SQL: SELECT \n",
      "    is.id AS inspection_scheduling_id,\n",
      "    is.date_of_inspection,\n",
      "    is.inspection_status,\n",
      "    is.inspection_type,\n",
      "    is.remarks,\n",
      "    fps.id AS fair_price_shop_id,\n",
      "    fps.fps_name,\n",
      "    fps.fps_uid,\n",
      "    p.panchayat_name,\n",
      "    p.panchayat_uid,\n",
      "    b.block_name,\n",
      "    b.block_uid,\n",
      "    sd.subdivision_name,\n",
      "    sd.subdivision_uid,\n",
      "    d.district_name,\n",
      "    d.district_uid,\n",
      "    creator.username AS assigned_by,\n",
      "    assignee.username AS assigned_to\n",
      "FROM \n",
      "    inspection_schedulings is\n",
      "JOIN \n",
      "    inspection_schedulings_fps_id_lnk isf ON is.id = isf.inspection_scheduling_id\n",
      "JOIN \n",
      "    fair_price_shops fps ON isf.fair_price_shop_id = fps.id\n",
      "JOIN \n",
      "    godowns_panchayat_lnk gpl ON fps.godown_id = gpl.godown_id\n",
      "JOIN \n",
      "    panchayats p ON gpl.panchayat_id = p.id\n",
      "JOIN \n",
      "    panchayats_block_lnk pbl ON p.id = pbl.panchayat_id\n",
      "JOIN \n",
      "    blocks b ON pbl.block_id = b.id\n",
      "JOIN \n",
      "    subdivisions sd ON b.subdivision_id = sd.id\n",
      "JOIN \n",
      "    districts d ON sd.district_id = d.id\n",
      "JOIN \n",
      "    inspection_schedulings_assigned_to_lnk isa ON is.id = isa.inspection_scheduling_id\n",
      "JOIN \n",
      "    poims_users assignee ON isa.poims_user_id = assignee.id\n",
      "JOIN \n",
      "    poims_users creator ON is.created_by_id = creator.id\n",
      "WHERE \n",
      "    is.date_of_inspection BETWEEN '2025-05-01' AND '2025-05-14'\n",
      "    AND d.id = 209\n",
      "    AND sd.id = 07001\n",
      "    AND b.id = 01116\n",
      "    AND p.id = 000377\n",
      "    AND creator.username = 'dayakarB'\n",
      "    AND assignee.id = 40015297\n",
      "ORDER BY \n",
      "    is.date_of_inspection, fps.fps_name;\n",
      "\n",
      "Refining SQL with Model 2...\n",
      "\n",
      "Refined SQL: SELECT \n",
      "    is.id AS inspection_scheduling_id,\n",
      "    is.date_of_inspection,\n",
      "    is.inspection_status,\n",
      "    is.inspection_type,\n",
      "    is.remarks,\n",
      "    fps.id AS fair_price_shop_id,\n",
      "    fps.fps_name,\n",
      "    fps.fps_uid,\n",
      "    p.panchayat_name,\n",
      "    p.panchayat_uid,\n",
      "    b.block_name,\n",
      "    b.block_uid,\n",
      "    sd.subdivision_name,\n",
      "    sd.subdivision_uid,\n",
      "    d.district_name,\n",
      "    d.district_uid,\n",
      "    creator.username AS assigned_by,\n",
      "    assignee.username AS assigned_to\n",
      "FROM \n",
      "    inspection_schedulings is\n",
      "JOIN \n",
      "    inspection_schedulings_fps_id_lnk isf ON is.id = isf.inspection_scheduling_id\n",
      "JOIN \n",
      "    fair_price_shops fps ON isf.fair_price_shop_id = fps.id\n",
      "JOIN \n",
      "    godowns_panchayat_lnk gpl ON fps.godown_id = gpl.godown_id\n",
      "JOIN \n",
      "    panchayats p ON gpl.panchayat_id = p.id\n",
      "JOIN \n",
      "    panchayats_block_lnk pbl ON p.id = pbl.panchayat_id\n",
      "JOIN \n",
      "    blocks b ON pbl.block_id = b.id\n",
      "JOIN \n",
      "    subdivisions sd ON b.subdivision_id = sd.id\n",
      "JOIN \n",
      "    districts d ON sd.district_id = d.id\n",
      "JOIN \n",
      "    inspection_schedulings_assigned_to_lnk isa ON is.id = isa.inspection_scheduling_id\n",
      "JOIN \n",
      "    poims_users assignee ON isa.poims_user_id = assignee.id\n",
      "JOIN \n",
      "    poims_users creator ON is.created_by_id = creator.id\n",
      "WHERE \n",
      "    is.date_of_inspection BETWEEN '2025-05-01' AND '2025-05-14'\n",
      "    AND d.id = 209\n",
      "    AND sd.id = 07001\n",
      "    AND b.id = 01116\n",
      "    AND p.id = 000377\n",
      "    AND creator.username = 'dayakarB'\n",
      "    AND assignee.id = 40015297\n",
      "ORDER BY \n",
      "    is.date_of_inspection, fps.fps_name;\n",
      "\n",
      "Validator chose Model 2's refined SQL\n"
     ]
    }
   ],
   "source": [
    "from engine.refiner import SQLRefiner\n",
    "\n",
    "def test_refiner(sql_query, value_mappings, model1=\"deepseek-chat\", model2=\"mistralai/Mistral-7B-Instruct-v0.3\", validator=\"gemini\"):\n",
    "    \"\"\"Test SQL refinement functionality with multiple LLMs\"\"\"\n",
    "    refiner = SQLRefiner()\n",
    "    \n",
    "    try:\n",
    "        # Refine SQL using Model 1\n",
    "        print(\"\\nRefining SQL with Model 1...\")\n",
    "        model1_results = refiner.main_refiner(sql_query, value_mappings, llm_model=model1)\n",
    "        print(\"\\nRefined SQL:\", model1_results['refined_sql'])\n",
    "        \n",
    "        # Refine SQL using Model 2\n",
    "        print(\"\\nRefining SQL with Model 2...\")\n",
    "        model2_results = refiner.main_refiner(sql_query, value_mappings, llm_model=model2)\n",
    "        print(\"\\nRefined SQL:\", model2_results['refined_sql'])\n",
    "        \n",
    "        # Use Validator to decide which refined SQL to use\n",
    "        decision_prompt = f\"\"\"Compare these two refined SQL queries for the given original SQL and value mappings, and choose the better one:\n",
    "        \n",
    "        Original SQL: {sql_query}\n",
    "        Value Mappings: {value_mappings}\n",
    "        \n",
    "        Query 1 (Model 1):\n",
    "        Refined SQL: {model1_results['refined_sql']}\n",
    "        \n",
    "        Query 2 (Model 2):\n",
    "        Refined SQL: {model2_results['refined_sql']}\n",
    "        \n",
    "        Consider the original sql, value mappings and the refined SQLs when making your decision.\n",
    "        Respond with only '1' or '2' to indicate which query is better.\"\"\"\n",
    "        \n",
    "        decision = generate_text(decision_prompt, model=validator)\n",
    "        \n",
    "        # Use the chosen refined SQL\n",
    "        if decision.strip() == '1':\n",
    "            print(\"\\nValidator chose Model 1's refined SQL\")\n",
    "            chosen_results = model1_results\n",
    "        else:\n",
    "            print(\"\\nValidator chose Model 2's refined SQL\")\n",
    "            chosen_results = model2_results\n",
    "        \n",
    "        return chosen_results['refined_sql']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if value_mappings:\n",
    "    refined_sql = test_refiner(generated_sql, value_mappings)\n",
    "else:\n",
    "    print(\"Skipping refinement as no value mappings were generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SQL Execution Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed: Only SELECT queries are allowed for security reasons\n"
     ]
    }
   ],
   "source": [
    "from engine.executor import SQLExecutor\n",
    "\n",
    "def test_executor(sql_query):\n",
    "    \"\"\"Test SQLExecutor functionality\"\"\"\n",
    "    executor = SQLExecutor()\n",
    "    \n",
    "    success, results, formatted_results, error = executor.main_executor(sql_query)\n",
    "    \n",
    "    if success:\n",
    "        print(f\"\\nSuccess! Found {len(results)} rows\")\n",
    "        print(\"\\nFormatted Results:\")\n",
    "        print(formatted_results)\n",
    "        print(\"\\nRaw Results:\")\n",
    "        print(results)\n",
    "        return results\n",
    "    else:\n",
    "        print(f\"\\nFailed: {error}\")\n",
    "        return None\n",
    "\n",
    "if refined_sql:\n",
    "    execution_results = test_executor(refined_sql)\n",
    "else:\n",
    "    print(\"Skipping execution as no refined SQL was generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Analysis Test with Multiple LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping analysis as no execution results were generated\n"
     ]
    }
   ],
   "source": [
    "from engine.analyzer import SQLAnalyzer\n",
    "\n",
    "def test_analyzer(query, results):\n",
    "    \"\"\"Test SQLAnalyzer functionality with DeepSeek\"\"\"\n",
    "    analyzer = SQLAnalyzer()\n",
    "    \n",
    "    try:\n",
    "        # Analyze results using DeepSeek\n",
    "        print(\"\\nAnalyzing results with DeepSeek...\")\n",
    "        mistral_results = analyzer.main_analyzer(query, results, llm_model=\"deepseek-chat\")\n",
    "        print(\"\\nAnalysis:\", mistral_results['analysis'])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "if execution_results:\n",
    "    test_analyzer(user_query, execution_results)\n",
    "else:\n",
    "    print(\"Skipping analysis as no execution results were generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LLM Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our last chat was about comparing two identical refined SQL queries for an FPS inspection report and selecting the better one (though they were the same).\n"
     ]
    }
   ],
   "source": [
    "# Define a prompt to test the conversation history\n",
    "prompt = \"What was our last chat about? Explain in a single sentence.\"\n",
    "response = generate_text(prompt, model=\"deepseek-chat\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
